<h1>Chapter 17. 샤딩 관리</h1>

복사 셋과 마찬가지로 샤드 클러스터를 관리하는 여러 옵션들이 있다.<br/>
수동 관리는 하나의 옵션이다.<br/>
요즘은 다양한 클러스터 관리 (옵스 매니저, 클라우드 매니저, 아틀라스 서비스형 데이터베이스) 등 도구가 점점 보편화 되고있다.<br/>
이번 장에서는 샤드 클러스터를 수동으로 관리하는 방법을 다룬다.<br/>

<h2>현재 상태 확인</h2>
데이터의 위치, 샤드 구성, 클러스터 실행 작업을 조회할 수 있는 몇가지 보조자가 있다.<br/>

<h3>sh.status()를 사용해 요약 정보 얻기</h3>
sh.status()를 샤드, 데이터베이스, 샤딩된 컬렉션의 개요를 제공한다.<br/>
청크의 개수가 적다면 어느 청크가 어디에 위치하는지도 출력한다.<br/>
단순히 컬렉션의 샤드 키와 각 샤드가 갖는 청크 개수를 보고한다.<br/>

```
> sh.status() ▶ 청크가 여러 개면 각 청크를 출력하기보다는 청크 상태를 요약한다.
              ▶ config 데이터베이스에서 수집한 정보를 모두 보여준다.
              
> sh.status(true) ▶ 모든 청크를 보려면 true를 넣는다. true를 입력하면 상세한 정보를 출력한다.
```

<h3>구성 정보 확인하기</h3>
클러스터에 대한 모든 구성 정보는 구성 서버의 config 데이터베이스 내 컬렉션에 보관된다.<br/>
셸 보조자를 사용하면 구성 정보를 더 읽기 쉽게 볼 수 있다. 하지만, 클러스터에 대한 메타데이터를 조회하려면 언제든지 config 데이터베이스를 직접 쿼리할 수 있다.<br/>

```
> use config
```

일반적으로 config 데이터베이스에 들어 있는 데이터는 직접 수정하면 안된다.<br/>
무언가를 수정하고 나면 모든 mongos 서버를 재시작해야 변경 사항이 적용된다.<br/>

다음은 config 데이터베이스는 몇 가지 컬렉션이 있다.<br/>

<h3>config.shards</h3>

shards 컬렉션은 클러스터 내 모든 샤드를 추적한다.

```
> db.shards.find()
{
  "_id" : "shard01", // 복제 셋의 이름 -> 고유해야함.
  "host" : "shard01/localhost:27018,localhost:27019,localhost:27020",
  "state" : 1
}
{
  "_id" : "shard02",
  "host" : "shard02/localhost:27021,localhost:27022,localhost:27023",
  "state" : 1
}

{
  "_id" : "shard03",
  "host" : "shard03/localhost:27024,localhost:27025,localhost:27026",
  "state" : 1
}
```

여기에서 shard의 _id는 복제 셋의 이름에서 가져온다. 그러므로 클러스터 안에 있는 각 복제 셋의 이름은 고유해야한다.

<h3>config.databases</h3>
database 컬렉션은 클러스터가 알고 있는 모든 샤딩 및 비샤딩 데이터베이스를 추적한다.

```
> db.databases.find()
{ "_id" :"video",
"primary":"shard02", ☞ primary 는 데이터베이스의 홈베이스
"partitioned":true,  ☞ enableSharding이 데이터베이스에 실행된 적이 있으면 partitioned 는 true가 된다.
..........
}
```

<h3>config.collections</h3>

collections 컬렉션은 모든 샤딩된 컬렉션을 추적한다.

```
> db.collections.find().pretty()
{
"_id": "video.movies", ☞ 컬렉션의 네임스페이스
...
"key" : {              ☞  샤드키. 여기서는 "imdbId"에 해시된 샤드 키.
  "imdbId":"hashed"
  },
"unique" : false,      ☞ 샤드 키가 고유한 인덱스는 아님을 나타낸다. 기본적으로 샤드키는 고유하지 않다.
...
}
```

<h3>config.chunks</h3>

chunks 컬렉션은 모든 컬렉션 내 모든 청크의 기록을 보관한다.

```
> db.chunks.find().skip(1).limit(1).pretty()
{
  "_id":"video.movies-imdbId_MinKey", ☞ 청크의 고유 식별자. 일반적으로 네임스페이스, 샤드 키, 하우 청크 범위다.
  "lastmod" : Timestamp(2,0),         ☞ 청크 버전 관리를 추적한다.
  "lastmodEpoch" : ObjectId("5db........"),
  "ns" :"video.movies",               ☞ 청크가 위치한 컬렉션
  "min":{
    "imdbid" : {"$minKey":1}          ☞ 청크 범위(경계포함) 내 최솟값
  },
  "max":{
    "imdbid" : {NumberLong("-72........") ☞ 청크 내 모든 값은 이 값보다 작다.
  },
  "shard" :"shard01",                 ☞ 청크가 위치한 샤드
  ... 
}
```

"lastmod"필드는 청크 버전 관리를 추적한다. <br/>
예를 들어, "video.movies-imdbId_MinKey" 청크가 두 개의 청크로 분할됐다면, 이전의 단일 청크와 분할돼서 작아진 "video.movies-imdbId_MinKey" 청크를 구별하는 방법이 필요하다.<br/>
따라서 Timestamp 값의 첫 번째 구성 요소는 청크가 새 샤드로 마이그레이션된 횟수를 반영한다.<br/>
두번째 구성 요소는 분할 수를 반영한다.<br/>
"lastmodEpoch" 필드는 컬렉션의 생성 시기를 지정하며, 컬렉션이 삭제되고 즉시 재생성될 때 동일한 컬렉션 이름에 대한 요청을 구별하는 데 사용된다.<br/>

<h3>config.changelog</h3>

changelog 컬렉션은 발생한 분할과 마이그레이션을 모두 기록하므로 클러스터가 무엇을 하고 있는지 추적하는데 유용하다.

1) 분할
```
> db.changelog.find({what:"split"}).pretty()
{
....
"detail" : {
    "before" : {
      ...
      "lastmod":Timestamp(9,1),
      "lastmodEpoch":Objectid("5bdf72c021b6e...")
    },
    "left" : {
      ...
      "lastmod":Timestamp(9,2),
      "lastmodEpoch":Objectid("5bdf72c021b6e...")    
    },
    "right" : {
      ...
      "lastmod":Timestamp(9,3),
      "lastmodEpoch":Objectid("5bdf72c021b6e...")    
    }
  }

}
```

각각의 새 청크에서 "lastmod"의 두번째 구성 요소가 갱신됐고, 값은 각각 Timestamp(9,2)와 Timestamp(9,3)이다.

마이그레이션은 더 복잡하며, 실제로 네 개로 나뉜 체인지로그 도큐먼트가 생긴다.<br/>
하나는 마이그레이션의 시작을 명시하고, 하나는 '원본' 샤드, 하나는 '목적지' 샤드, 나머지 하나는 마이그레이션에 대한 '커밋 정보'를 포함한다.<br/>
'원본'샤드와 '목적지'샤드에 대한 도큐먼트는 프로세스에서 단계별로 소요된 시간의 명세를 제공한다.<br/>
이를 통해 마이그레이션에서 병목 현상을 일으키는 원인이 디스크인지, 네트워크 혹은 다른 무언가인지 추정할 수 있다.<br/>

<b>예를 들어 '원본' 샤드에 의해 생성된 도큐먼트는 다음과 같다.</b>

```
> db.changelog.findOne({what:"moveChunk.to"}) // 원본 샤드에서 생성된 도큐먼트
{
  ...
  "what":"moveChunk.to",
  "ns" : "video.movies", //위치
  ...
  "detail" : {
  ...
    "step 1 of 6" : 965,
    "step 2 of 6" : 608,
    "step 2 of 6" : 15424,
    "step 4 of 6" : 0,
    "step 5 of 6" : 72,
    "step 6 of 6" : 258,
    "note":"success"
    }
}
```

"detail"에 나열된 각 단계에서 시간이 기록되며 "stepN of N"메세지는 단계의 소요 시간을 밀리초 단위로 보여준다.

'원본'샤드가 mongos로부터 moveChunk 명령을 받으면 다음과 같은 작업을 수행한다.<br/>
1. 명령 매개변수를 확인한다.<br/>
2. 구성 서버가 마이그레이션을 위해 분산된 락을 획득할 수 있는지 확인한다.<br/>
3. '목적지' 샤드에 접속을 시도한다.<br/>
4. 데이터를 복사한다. 이는 'the critical section'으로 명시돼 기록된다.<br/>
5. '목적지' 샤드 및 구성 서버와 조정해 이동을 확정한다.<br/>

'목적지'와 '원본'샤드는 "step 4 of 6"부터는 서로 통신이 가능한 상태여야 한다.<br/>
마지막 단계에서 원본 서버의 네트워크 연결이 비정상적이라면, 마이그레이션을 되돌리거나 계속 진행할 수 없는 상태가 된다.<br/>
이럴 때 mongod가 종료된다.<br/>

<b>'목적지' 샤드의 changelog 도큐먼트는 '원본' 샤드의 changelog 도큐먼트와 비슷하지만 단계가 약간 다르다.</b>

```
> db.changelog.find({what:"moveChunk.from","details.max.imdbId": .....).pretty()
{
  ...
  "what":"moveChunk.from",
  "ns":"video.movies",
  "detail" : {
  ...
    "step 1 of 6" : 0,
    "step 2 of 6" : 4,
    "step 2 of 6" : 191,
    "step 4 of 6" : 17000,
    "step 5 of 6" : 341,
    "step 6 of 6" : 39,
    "to:"shard01"
    "from":"shard02",
    "note":"success"
  }

}
```

'목적지' 샤드가 '원본'샤드로부터 명령을 받으면 다음 작업을 수행한다.<br/>
1. 인덱스를 마이그레이션한다. <br/>
2. 청크 범위 안에 있는 모든 데이터를 삭제한다.<br/>
3. 청크 내 모든 도큐먼트를 '목적지' 샤드로 복사한다.<br/>
4. 복사하는 동안에 도큐먼트에 일어난 작업을 재실행한다.<br/>
5. '목적지' 샤드가 새로 마이그레이션된 데이터를 대부분의 서버로 복제하도록 기다린다.<br/>
6. 청크의 메타데이터가 '목적지' 샤드에 위치한다고 바꿔서 마이그레이션을 확정한다.<br/>

<h3>config.settings</h3>
현재의 밸런서 설정과 청크 크기를 나타내는 도큐먼트를 포함한다.<br/>
컬렉션 내 도큐먼트를 변경해서 밸런서를 켜고 끄거나 청크 크기를 변경할 수 있다.<br/>
컬렉션 안의 값을 변경할 때 구성 서버에 직접 연결하지 말고 항상 mongos에 연결해야함을 명시하자.<br/>

<h2>네트워크 연결 추적</h2>
<h3>연결 통계 정보 얻어오기</h3>

connPoolStats 명령은 현재 데이터베이스 인스턴스에서 샤드 클러스터나 복제 셋의 다른 멤버로 나가는 열린 연결에 대한 정보를 반환한다.<br/>
connPoolStats는 실행 중인 작업과 간섭을 피하려고 락을 사용하지 않는다.<br/>
따라서 connPoolStats가 정보를 수집할 때 개수가 약간 바뀌어, 호스트와 풀 연결 개수 간에 약간의 차이가 생길 수 있다.<br/>

```
> db.adminCommnad({"connPoolStats":1})
{
  "numClientConnections" : 10,  ☞ 인스턴스에서 샤드 클러스터나 복제 셋의 다른 구성원으로 나가는 활성 및 저장된 동기 연결 수.     
  "numAScopedConnections": 0,   ☞ 인스턴스에서 샤드 클러스터나 복제 셋으 다른 구성원으로 나가는 활성 및 저장된 범위 동기 연결 수,
  "totalInUse": 0,              ☞ 인스턴스에서 현재 사용 중인 샤드 클러스터나 복제 셋의 다른 구성원으로 나가는 총 연결 수.
  "totalAvailable" : 13,        ☞ 샤드 클러스터나 복제 셋의 다른 구성원으로 나가는 사용 가능한 총 발신 연결 수를 나타낸다.
  "totalCreated": 86,           ☞ 샤드 클러스터나 복제 셋의 다른 구성원으로 생성한 총 발신 연결 수를 나타낸다.
  "totalRefreshing": 0,         ☞ 인스터스에서 현재 새로 새로고침되는 샤드 클러스터나 복제셋의 다른 구성원으로 나가는 총 발신 연결 수.
  "pools" : {
    ........
    "localhost:27017" : {
      "inUse" : 0,             ☞ 호스트 단위의 사용중
      "available:1,            ☞ 호스트 단위의 사용 가능
      "created":1,             ☞ 호스트 단위의 생성됨
      "refreshing":0           ☞ 호스트 단위의 새로고침
    }
    ...........
}
```

<h3>연결 개수 제한하기</h3>
클라이언트가 mongos에 접속하면 mongos는 클라이언트의 요청을 전달하려고 적어도 하나의 샤드에 연결을 생성한다.  <br/>
따라서 mongos에 들어온 각 클라이언트 연결은 mongos에서 샤드로 나가는 연결을 적어도 한 개는 만든다.<br/>

mongos 프로세스가 여러 개면 샤드가 다룰 수 잇는 양보다 더 많은 연결을 생성할 수도 있다.
기본적으로 mongos는 최대 6만 5536개의 연결을 허용하며, 각각 1만 개의 클라이언트 연결을 갖는 5개의 mongos 프로세스가 있다면 하나의 샤드에
5만 개의 연결 생성을 시도한다.

이를 방지하려면 mongos 명령행 구성에서 --maxConns 옵션을 사용해 생성 가능한 연결 개수를 제한하면 된다.

다음 공식은 하나의 mongos에서 샤드가 다룰 수 잇는 연결의 최대 수를 계산하는 데 사용한다.
- maxConns = maxConnsPrimary - (numMembersPerReplicaSet x 3)
- (other x 3) / numMongosProcesses : 부수적인 역할을 하는 프로세스 개수 / 샤드클러스터에서 mongos의 총 개수

maxConnsPrimary : 프라이머리의 최대 연결수. 일반적으로 2만으로 설정한다.
(numMembersPerReplicaSet x 3) : 프라이머리는 각 세컨더리에 연결을 하나씩 생성하고, 세컨더리는 프라이머리에 두 개의 연결을 생성해서 총 3개의 연결이 있다.
(other x 3) : other는 모니터링이나 백업 에이전트와 같이 mongod에 접속하거나, 직접 셸에 역녈하거나, 이동을 위해 다른 샤드로 연결하는 등 부수적인 역할을 하는 프로세스
개수이다.
numMongosProcesses : 샤드 클라스터에서 mongos의 총 개수

--maxConns는 단지 mongos가 연결을 이 이상 생성하지 않도록 함을 명심하자.
한계에 이를때 특별히 도움되는 동작을 하지 않으며, 그저 요청을 막고 연결이 해제되기를 기다린다.
그러므로 애플리케이션이 너무 많은 연결을 사용하지 못하게 해야한다. 

<h2>서버 관리</h2>
클러스터가 커지면 용량을 추가하거나 구성을 바꿀 필요가 있다.
<h3>서버 추가</h3>
언제든지 새로운 mongos 프로세스를 추가할 수 있다.

<h3>샤드의 서버 변경</h3>
샤드 클러스터를 사용할 때, 각 샤드에서 서버를 변경할 수도 있다.
샤드의 멤버 구성을 변경하려면 샤드의 프라이머리에 직접 연결해 복제 셋을 재구성하자. 클러스터 구성은 변경 사항을 가져와서 config.shards를 자동으로 수정한다.
수동으로 config.shards를 수정하지 않도록 주의하자.

<h3>샤드를 독립 실행형 서버에서 복제셋을 변경하기</h3>
가장 쉬운 방법은 빈 복제 셋 샤드를 새로 추가하고 독립 실행형 서버 샤드를 제겋나느 방법이다.

<h3>샤드 제거</h3>
일반적으로 샤드는 클러스터에서 제거되면 안된다.<br/>
주기적으로 샤드를 추가하거나 제거하면 시스템에 필요 이상으로 무리를 준다.<br/>
너무 많은 샤드를 추가한다면, 제거했다가 나중에 다시 추가하지 말고 샤드 안에서 시스템이 커지도록 하는 편이 낫다.<br/>
하지만, 필요시에 샤드를 제거할 수 있다.<br/>

벨런서가 커진 것을 확인하고 밸런서는 배출이라는 프로세스에서 제거하려는 샤드의 모든 데이터를 다른 샤드로 이동하는 임무가 있다.<br/>
배출을 시작하려면 removeShard 명령을 실행한다.<br/>
removeShard는 샤드명을 가져와서 샤드의 모든 청크를 다른 샤들 배출한다.<br/>

```
// shard03 -> shard02로 배출
> db.adminCommand({"removeShard":"shard03"})
{
..........
"state:"started",
"shard" : "shard03",
"note" : "you need to drop or movePrimary these database",
..........
}
//
> db.adminCommand({"removeShard":"shard02"})
{
..........
"state:"ongoing",
..........
}
```

removeShard는 원하는 만큼 여러 번 실행할 수 있다.<br/>
청크를 옮기려면 분할해야 할 수도 있으므로, 배출하는 동안 시스템에서 청크 개수를 증가할 수도 있다.<br/>

```
// 샤드가 5개인 클러스터에서 청크가 다음처럼 분포한다고 가정한다. (총 52개)
test-rs0 10
test-rs1 10
test-rs2 10
test-rs3 11
test-rs4 11

// test-rs3를 제거한다면?
test-rs0 15
test-rs1 15
test-rs2 15
test-rs4 15
// 11개는 원래 있었고(test-rs3) 7개는 분할에서 생성됐다.
// 클러스터에서 이제 60개의 청크가 있고, 그 중 18(11+7)개는 test-rs3에서 나왔다.
```

모든 청크가 옮겨졌으면, 제거된 샤드를 프라이머리로 하는 데이터베이스가 있다면 샤드를 제거하기 전에 먼저 제거해야 한다.<br/>
제거하려는 샤드가 클러스터 데이터베이스 중 하나의 프라이머리이면 removeShard는 "dbsToMove" 필드에 데이터베이스를 나열한다.<br/>
샤드 제거를 완료하려면 샤드에서 모든 데이터를 마이그레이션한 후 데이터베이스를 새 샤드로 이동하거나,<br/>
데이터베이스를 삭제해야한다.

```
> db.adminCommand({"removeShard":"shard02"})
{
...
"state":"ongoing",
...
"dbstoMove": [ "video" ] ,
...
}
//제거를 완료하려면 movePrimary를 사용해 나열된 데이터베이스를 이동한다.
> db.adminCommand({"movePrimary":"video","to":"shard01"}) 

// 다시 데이터베이스를 다 옮겼으면 removeShard를 한 번 더 실행해본다.
// 이 과정은 꼭 필요하지는 않지만, 처리가 완료되었는지 확인 할 수 있다.
> db.adminCommand({"removeShard":"shard02"})
{
...
"state":"completed",
"shard":"shard03",
...
}

```

<h2>데이터 밸런싱</h2>
일반적으로 몽고 DB는 자동적으로 데이터를 균등하게 분산한다. 이 절에서는 자동 밸런싱 작업을 켜고 끄는 방법과 밸런싱 과정에 개입하는 방법을 다룬다.

<h3>밸런서</h3>
대부분의 관리 작업에서는 밸런서를 끄는 작업이 선행된다.

```
> sh.setBalancerState(false) ▶ 밸런서를 끈다.
```

밸런서가 꺼진 상태에서는 새로운 밸런싱 작업이 시작되지 않는다.<br/>
하지만 진행 중에 밸런서를 끄면 밸런싱 작업이 강제로 중지되지 않는다.<br/>
따라서 config.locks 컬렉션을 확인해 밸런싱 작업이 아직 진행중인지 확인해야 한다.<br/>


```
// 끄지 전에 확인!
> db.locks.find({"_id":"balancer"})["state"]
0 // 0은 밸런서가 꺼져 있음을 의미
```

밸런싱 작업은 시스템에 부하를 준다.<br/>
목적지 샤드는 원본 샤드 청크 안에 있는 모든 두큐먼트를 쿼리하고 목적지 샤드에 입력해야 한다.<br/>
그리고 원본 샤드는 도큐먼트를 삭제해야한다.<br/>

마이그레이션이 애플리케이션 성능에 영향을 미친닥 판단하면 config.settings 컬렉션에서 밸런싱 작업할 시간대를 예약하자.

ex) 밸런싱 작업이 오후 1시에서 4시 사이에 실행되도록 다음 갱신을 실행하자.
```
// 먼저 켜져있는지 확인
> sh.setBalancerState(true)
// 시간대를 설정하자
> db.settings.update(
  {_id : "balancer"},
  {$set : {activeWindow : {start : "13:00", stop :"16:00"} } }.
  {upsert : true}
)
```

자동 밸런서는 항상 셋의 현재 상태를 기준으로 무엇을 이동할지 결정하며, 셋의 이력을 고려하지 않는다.<br/>
예를 들어 각각 500개의 청크를 갖는 shardA와 shardB가 있다고 가정했을 때,<br/>
shrardA가 많은 쓰기 요청을 받게 돼 밸런서를 '끄고' 가장 활발한 청크 30개를 shardB로 옮겼다.<br/>
이때 다시 밸런서를 '켜면' 청크 개수를 맞추려고 밸런서는 즉시 30개의 청크를 낚아채서 shardB 에서 shardA로 이동한다.<br/>

이를 방지하려면 밸런서를 시작하기 전에 활발하지 않은 청크 30개를 shardB에서 shardA로 옮기면 된다.<br/>
그러면 샤드 간 불균형은 없고 밸런서는 청크를 그대로 둔다.<br/>

<h3>청크 크기 변경</h3>
청크에는 도큐먼트가 0개에서 수백만개까지 존재할 수 있다.<br/>
일반적으로 청크가 클수록 다른 샤드로 이동하는데 시간이 많이 걸린다.<br/>

기본적으로 청크 크기는 64메가바이트며, 마이그레이션 용이성과 대규모 마이그레이션을 적절히 고려해 정한 수치다.<br/>
때로는 64메가바이트 청크로는 마이그레이션이 너무 오래 걸린다. <br/>
청크 크기를 줄여서 속도를 높일 수 있다.<br/>
셸을 통해서 mongos에 연결하고 config.settings 컬렉션을 다음처럼 변경하자.<br/>

ex) 64메가바이트에서 32메가바이트로 변경한다.
```
> db.settings.findOne()

> db.settings.save({"_id":"chunksize", "value":32})
```

하지만 기존 청크가 즉시 변경되지 않는다.<br/>
자동 분할은 삽입이나 갱신을 할 때만 발생한다.<br/>
따라서 청크 크기를 줄이고 나서 모든 청크가 새로운 크기로 분할되는 데는 시간이 걸린다.<br/>

분할은 취소할 수 없다.<br/>
청크 크기를 늘리면 기존 청크는 새 크기에 이를 때까지 삽입이나 갱신을 통해서 커진다.<br/>
청크 크기의 허용 범위는 1~1024 메가바이트다.<br/>

이는 모든 컬렉션과 데이터베이스에 영향을 미치는 클러스터 전역 설정이다.

<h3>청크 이동</h3>
청크 내 모든 데이터는 특정 샤드에 자리 잡는다.<br/>
그 샤드가 다른 샤드보다 더 많은 청크를 가지면 몽고DB는 읿루 청크를 옮겨버린다.<br/>

```
> sh.moveChunk("video.movies", {imdbId : 500000}, "shard02")
```

imdbId가 500000인 도큐먼트가 포함된 청크를 shard02로 이동한다.옮길 청크를 찾으려면 샤드 키를 사용해야 한다.<br/>
가장 쉬운 방법은 청크의 하한값으로 지저하는 방법이다.<br/>
이 명령은 결과를 반환하기 전에 청크를 이동하기 때문에 실행하는데 시간이 걸린다.<br/>

```
> sh.moveChunk("video.movies" , {imdbId : NumberLong("83..."}, "shard02")
{
   "cause" : {
      "chunkTooBig":true,
      .........
      "errMsg" : "chunk too big to move"
      }
}
```

청크를 옮기기 전에 splitAt명령을 사용해 수동으로 분할해야 한다.

```
> db.chunk.find({ns : "video.movies","min.imdbId":NumberLong("6386...")}).pretty()
{
  ...
  "min" : {"imdbId" : NumberLong("6386...") },
  "max" : {"imdbId" : NumberLong("8345...") },
  ...
}

> sh.splitAt("video.movies", {"imdbIid": NumberLong("70000000000")})

> sh.splitAt("video.movies", {"imdbIid": NumberLong("6386...")})
{
  ...
  "min" : {"imdbId" : NumberLong("6386...") },
  "max" : {"imdbId" : NumberLong("70000000000") },
  ...
}
```

청크가 작은 조각으로 분할되고 나면 옮길 수 있다.
최대 청크 크기를 늘린 후 옮길 수도 있지만, 큰 청크는 쪼갤 수 있을 때마다 쪼개야한다.

<h3>점보 청크</h3>
샤드 키로 'date'필드를 선택했다고 가정하자.<br/>
date 필드는 '년/월/일'처럼 보이는 문자열이며, mongos는 청크를 하루에 한 개까지만 생성할 수 있다. 이는 대체로 문제가 없지만, <br/>
갑자기 평소보다 1000배나 많은 트래픽을 받으면 문제가 생긴다.<br/>

이날의 청크는 다른 날보다 훨씬 커지지만 모든 도큐먼트가 샤드 키로 동일한 값을 갖기 때문에 전혀 분할되지 않는다.<br/>
청크는 config.settings에 설정된 최대 청크 크기보다 커지면 밸런서는 청크를 이동할 수 없다.<br/>
나눌 수도, 옮길 수도 없는 이 청크를 점보 청크라고 한다.<br/>

예를 들어 shard1, shard2, shard3과 같이 세 개의 샤드가 있다고 가정했을때, <br/>
핫스팟 샤드 키 패턴을 사용하면 모든 쓰기는 하나의 샤드로 몰린다.(shard1) <br/>
샤드 프라이머리 mongod는 다른 샤드들 간에 새 최상위 청크를 균등하게 이동하도록<br/>
밸런서에 요청한다. 밸런서는 점보 청크가 아닌 청크만 옮길 수 있으므로, 청크가 많은 샤드에서 작은 청크를 모두 이동한다.<br/>

모든 샤드의 청크 개수는 대략 비슷하지만 shard2와 shard3의 청크는 모두 크기가 64메가바이트보다 작다.<br/>
그리고 점보 청크가 생성된다면 shard1의 청크 크기는 점점 더 커져서 64메가바이트 이상이 된다.<br/>
따라서 세 개 샤드에 있는 청크 개수가 완전히 균등하더라도 shard1은 다른 두 샤드보다 훨씬 빨리 차오른다.<br/>

```
// 점보 청크가 있는지 sh.status()로 확인할 수 있으며 점보 청크는 jumbo라고 표시된다.
> sh.status()
...
  {"x": -7} --> {"x": 5 } on : shard0001
  {"x": 5} --> {"x": 6 } on : shard0001 jumbo
  {"x": 6} --> {"x": 7 } on : shard0001 jumbo
  {"x": 7} --> {"x": 339 } on : shard0001
...
```

<h3>점보 청크 분산하기</h3>
점보 청크 때문에 균형이 깨진 클러스터를 바로잡으러면 샤드 간에 점보 청크를 고르게 분산해야 한다.

점보 청크가 있는 샤드는 원본 샤드로 간주한다.
점보 청크가 마이그레이션할 샤드는 목적지 샤드라고 한다.
청크를 옮기려는 원ㄴ본 샤드가 여러개일 수 있다는 점을 알아두자.

1) 밸런서를 종료한다. 이 과정이 진행되는 동안 밸런서의 도움은 필요하지 않다.
> sh.setBalancerState(false)
2) 최대 청크보다 큰 청크를 옮기는 것을 허용하지 않으므로 청크 크기를 일시적을 늘린다.
> db.settings.save({"_id":"chunksize","value":10000})
3) moveChunk 명령으로 점보 청크를 '원본'샤드에서 옮긴다.
4) '목적지' 샤드들과 청크 개수가 비슷해질 때까지 원본 샤드에 남아있는 청크에 splitChunk를 실행한다.
5) 청크 크기를 원래 값으로 설정한다.
> db.settings.save({"_id":"chunksize","value":64});=
6) 밸런서를 켠다.
> sh.setBalancerState(true)

밸런서가 다시 켜지면 다시 점보 청크를 이동할 수 없게 된다.

<h4>점보 청크 방지하기</h4>
보관하는 데이터의 양이 많아질수록 앞에서 설명한 수작업으로는 처리하기 힘들어진다.
그러므로 점보 청크가 문제가 된다면 형성되지 전에 방지해야 한다.

<h3>구성 갱신</h3>
때로는 mongos가 구성 서버에서 가져온 구성을 올바르게 갱신하지 않는다.
flushRouterConfig 명령으로 수동으로 모든 캐시를 정리한다.
> db.adminCommand({"flushRouterConfig" : 1 } )
